{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Encoder\n",
    "\n",
    "Let's begin by importing tensorflow and the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (14, 28)\n",
    "import IPython\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "from tensorflow.contrib.signal.python.ops import window_ops\n",
    "\n",
    "from network.sequentialModel import SequentialModel\n",
    "from network.stftGapContextEncoder import StftGapContextEncoder\n",
    "from utils.strechableNumpyArray import StrechableNumpyArray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize the context encoder network and select the step we want to use for the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000\n",
    "start_in_seconds = 0.1\n",
    "side_length = 2048\n",
    "gap_length = 1024\n",
    "window_size = side_length*2+gap_length\n",
    "starting_sample_left_side = int(sr*start_in_seconds)\n",
    "ending_sample_left_side = starting_sample_left_side + side_length\n",
    "starting_sample_right_side = ending_sample_left_side + gap_length\n",
    "ending_sample_right_side = starting_sample_right_side + side_length\n",
    "\n",
    "best_step =  # insert best step\n",
    "batch_size = 256\n",
    "fft_frame_length = 512\n",
    "fft_frame_step = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "aTargetModel = SequentialModel(shapeOfInput=(batch_size, window_size), name=\"Target Model\")\n",
    "\n",
    "with tf.name_scope('Remove_unnecesary_sides_before_stft'):\n",
    "    signal = aTargetModel.output()\n",
    "    signal_without_unnecesary_sides = signal[:, 1664:3456]\n",
    "    aTargetModel.setOutputTo(signal_without_unnecesary_sides)\n",
    "aTargetModel.addSTFT(frame_length=fft_frame_length, frame_step=fft_frame_step)\n",
    "aTargetModel.divideComplexOutputIntoRealAndImaginaryParts()  # (256, 11, 257, 2)\n",
    "\n",
    "aModel = SequentialModel(shapeOfInput=(batch_size, window_size), name=\"context encoder\")\n",
    "\n",
    "with tf.name_scope('Remove_gap_before_stft'):\n",
    "    signal = aModel.output()\n",
    "    left_side = signal[:, :2048]\n",
    "    right_side = signal[:, 2048+1024:]\n",
    "    \n",
    "    # This is strange. The window is 5K samples long, the hole 1024 and the 0 pading 384.\n",
    "    # Unless signal in in spectrogram. In that case, the code is not very clear. Maybe consider adding comments.\n",
    "    left_side_padded = tf.concat((left_side, tf.zeros((batch_size, 384))), axis=1)\n",
    "    right_side_padded = tf.concat((tf.zeros((batch_size, 384)), right_side), axis=1)\n",
    "\n",
    "    # If you pad them with 0, maybe you also stack them allong axis 2 (one after the other.)\n",
    "    signal_without_gap = tf.stack((left_side_padded, right_side_padded), axis=1)  # (256, 2, 2432)\n",
    "    aModel.setOutputTo(signal_without_gap)\n",
    "\n",
    "aModel.addSTFT(frame_length=fft_frame_length, frame_step=fft_frame_step)  # (256, 2, 16, 257)\n",
    "aModel.addReshape((batch_size, 32, 257))\n",
    "aModel.divideComplexOutputIntoRealAndImaginaryParts()  # (256, 32, 257, 2)\n",
    "aModel.addReshape((batch_size, 16, 257, 4))\n",
    "\n",
    "with tf.variable_scope(\"Encoder\"):\n",
    "    filter_shapes = [(7, 89), (3, 17), (2, 11), (1, 9), (1, 5), (2, 5)]\n",
    "    input_channels = [4, 32, 128, 512, 256, 160]\n",
    "    output_channels = [32, 128, 512, 256, 160, 128]\n",
    "    strides = [[1, 2, 2, 1], [1, 2, 3, 1], [1, 2, 3, 1], [1, 1, 2, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n",
    "    names = ['First_Conv', 'Second_Conv', 'Third_Conv', 'Fourth_Conv', 'Fifth_Conv', 'Sixth_Conv']\n",
    "    aModel.addSeveralConvLayers(filter_shapes=filter_shapes, input_channels=input_channels,\n",
    "                                output_channels=output_channels, strides=strides, names=names)\n",
    "\n",
    "aModel.addReshape((batch_size, 2048))\n",
    "aModel.addFullyConnectedLayer(2048, 2048, 'Fully')\n",
    "aModel.addRelu()\n",
    "aModel.addBatchNormalization()\n",
    "aModel.addReshape((batch_size, 8, 8, 32))\n",
    "\n",
    "with tf.variable_scope(\"Decoder\"):\n",
    "    filter_shapes = [(8, 8), (5, 5), (3, 3)]\n",
    "    input_channels = [32, 128, 512]\n",
    "    output_channels = [128, 512, 257]\n",
    "    strides = [[1, 2, 2, 1], [1, 2, 2, 1], [1, 1, 1, 1]]\n",
    "    names = ['First_Deconv', 'Second_Deconv', 'Third_Deconv']\n",
    "    aModel.addSeveralDeconvLayers(filter_shapes=filter_shapes, input_channels=input_channels,\n",
    "                                  output_channels=output_channels, strides=strides, names=names)\n",
    "\n",
    "    aModel.addReshape((batch_size, 8, 257, 128))\n",
    "    aModel.addDeconvLayer(filter_shape=(5, 67), input_channels=128, output_channels=11, stride=(1, 2, 2, 1),\n",
    "                          name='Fourth_deconv')\n",
    "    aModel.addBatchNormalization()\n",
    "\n",
    "    aModel.addReshape((batch_size, 11, 257, 32))\n",
    "\n",
    "    aModel.addDeconvLayerWithoutNonLin(filter_shape=(11, 257), input_channels=32, output_channels=2,\n",
    "                                       stride=(1, 1, 1, 1), name=\"Last_Deconv\")\n",
    "\n",
    "print(aModel.description())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aContextEncoderNetwork = StftGapContextEncoder(model=aModel, batch_size=batch_size, target_model=aTargetModel, window_size=window_size,\n",
    "                                               gap_length=gap_length, learning_rate=1e-4, name='nat_stft_gap_big_fma_2_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToDatasetFolder = 'fma-test'\n",
    "audios = np.zeros((0,8000), dtype=np.float32)\n",
    "i = 0\n",
    "total = 0\n",
    "file_names = []\n",
    "for file_name in os.listdir(pathToDatasetFolder):\n",
    "    if file_name.endswith('.mp3'):  \n",
    "        file_names.append(file_name)\n",
    "        audio, sr = librosa.load(pathToDatasetFolder + '/' + file_name, sr=None)\n",
    "        \n",
    "        if np.sum(np.absolute(audio[ending_sample_left_side:starting_sample_right_side])) < gap_length*1e-3: \n",
    "            print(file_name, \"doesn't meet the minimum amplitude requirement\")\n",
    "            continue\n",
    "        if len(audio) < 8000:\n",
    "            continue\n",
    "        audios = np.append(audios, [audio[:8000]], 0)\n",
    "        i+=1\n",
    "        \n",
    "        if i > 500:\n",
    "            i -= 500\n",
    "            total += 500\n",
    "            print(\"500 plus!\", total)\n",
    "\n",
    "print(\"there were: \", total+i)\n",
    "\n",
    "print(audios.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = audios[:, starting_sample_left_side:ending_sample_right_side]\n",
    "left_side = audios[:, starting_sample_left_side:ending_sample_left_side]\n",
    "right_side = audios[:, starting_sample_right_side:ending_sample_right_side]\n",
    "sides = np.concatenate((left_side, right_side), axis=1)\n",
    "original_gaps = audios[:, ending_sample_left_side:starting_sample_right_side]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_count = 39\n",
    "reconstructed_spec = aContextEncoderNetwork.reconstructAudio(window, best_step, max_batchs=batch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reconstructed_spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_original_stft = tf.contrib.signal.stft(signals=window[:len(reconstructed_spec)], frame_length=fft_frame_length, frame_step=fft_frame_step)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    original_stft = sess.run(tf_original_stft)\n",
    "    \n",
    "print(original_stft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_spec = reconstructed_spec[:,:,:,0]+1.0j*reconstructed_spec[:,:,:,1]\n",
    "\n",
    "reconstructed_spec_window = np.concatenate((original_stft[:, :13, :], \n",
    "                                   gap_spec, \n",
    "                                   original_stft[:, 24:, :]), axis=1)\n",
    "print(reconstructed_spec_window.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "window_fn = functools.partial(window_ops.hann_window, periodic=True)\n",
    "inverse_window = tf.contrib.signal.inverse_stft_window_fn(fft_frame_step,\n",
    "                                           forward_window_fn=window_fn)\n",
    "rec_stft = reconstructed_spec[:,:,:,0] + 1.0j*reconstructed_spec[:,:,:,1]\n",
    "ori_stft = original_stft[:, 13:24, :] \n",
    "print(rec_stft.shape)\n",
    "print(ori_stft.shape)\n",
    "\n",
    "shape = (batch_size, 11, 257)\n",
    "stft_to_invert = tf.placeholder(tf.complex64, shape=shape, name='stft_to_invert')\n",
    "tf_reconstructed_signals = tf.contrib.signal.inverse_stft(stfts=stft_to_invert, frame_length=fft_frame_length, frame_step=fft_frame_step,\n",
    "                                                         window_fn=inverse_window)\n",
    "\n",
    "reconstructed_signal = np.zeros([0,1792], dtype=float32)\n",
    "original_signal = np.zeros([0,1792], dtype=float32)\n",
    "with tf.Session() as sess:\n",
    "    for i in range(int(len(rec_stft)/batch_size)):\n",
    "        feed_dict = {stft_to_invert: rec_stft[i*batch_size:(i+1)*batch_size]}\n",
    "        reconstructed_signal = np.append(reconstructed_signal, sess.run(tf_reconstructed_signals, feed_dict=feed_dict), axis=0)\n",
    "        \n",
    "        feed_dict = {stft_to_invert: ori_stft[i*batch_size:(i+1)*batch_size]}\n",
    "        original_signal = np.append(original_signal, sess.run(tf_reconstructed_signals, feed_dict=feed_dict), axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reconstructed_signal.shape)\n",
    "print(original_signal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_gaps = reconstructed_signal[:, 384:-384]\n",
    "original_gaps = original_signal[:, 384:-384]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reconstructed_signal.shape)\n",
    "print(original_signal.shape)\n",
    "print(reconstructed_spec.shape)\n",
    "print(original_stft.shape)\n",
    "print(len(reconstructed_signal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pavlovs_SNR(y_orig, y_inp, onAxis=(1,)):\n",
    "    norm_y_orig = _squaredEuclideanNorm(y_orig, onAxis)\n",
    "    norm_y_orig_minus_y_inp = _squaredEuclideanNorm(y_orig - y_inp, onAxis)\n",
    "    return 10 * np.log10(norm_y_orig / norm_y_orig_minus_y_inp)\n",
    "\n",
    "def _squaredEuclideanNorm(vector, onAxis=(1,)):\n",
    "    squared = np.square(vector)\n",
    "    summed = np.sum(squared, axis=onAxis)\n",
    "    return summed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_a = reconstructed_gaps\n",
    "gap = original_gaps[:int(batch_count*batch_size)]\n",
    "\n",
    "SNRs = _pavlovs_SNR(gap, fake_a)\n",
    "\n",
    "\n",
    "print(SNRs.shape)\n",
    "print(SNRs.mean())\n",
    "print(SNRs.std())\n",
    "print(SNRs.min())\n",
    "print(np.percentile(SNRs, [25, 50, 75]))\n",
    "print(SNRs.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_side = audios[:len(reconstructed_gaps), :ending_sample_left_side]\n",
    "right_side = audios[:len(reconstructed_gaps), starting_sample_right_side:]\n",
    "reconstructed_signals = np.concatenate((left_side, reconstructed_gaps, right_side), axis=1)\n",
    "zeroed_signals = np.concatenate((left_side, (reconstructed_gaps)*0, right_side), axis=1)\n",
    "reconstructed_original = np.concatenate((left_side, original_gaps[:len(reconstructed_gaps)], right_side), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Write files to disk\"\"\"\n",
    "maximum = 256\n",
    "\n",
    "maxv = np.iinfo(np.int16).max\n",
    "for index in range(min(len(reconstructed_signals), maximum)):\n",
    "    librosa.output.write_wav(\"recs/original_\" + file_names[index] + \".wav\", (audios[index] * maxv).astype(np.int16), sr)\n",
    "    librosa.output.write_wav(\"recs/reconstructed_\" + file_names[index] + \".wav\", (reconstructed_signals[index] * maxv).astype(np.int16), sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_signal_to_evaluate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, 3, sharey='row', figsize=(18, 12))\n",
    "\n",
    "difference = original_gaps[reconstructed_signal_to_evaluate]-reconstructed_gaps[reconstructed_signal_to_evaluate]\n",
    "\n",
    "axarr[0].plot(original_gaps[reconstructed_signal_to_evaluate])\n",
    "axarr[0].set_title('original gap', size=24)\n",
    "axarr[1].plot(reconstructed_gaps[reconstructed_signal_to_evaluate])\n",
    "axarr[1].set_title('reconstructed gap', size=24)\n",
    "axarr[2].plot(difference)\n",
    "axarr[2].set_title('difference', size=24)\n",
    "\n",
    "print(np.sum(np.absolute(original_gaps[reconstructed_signal_to_evaluate])))\n",
    "print(np.absolute(difference).sum())\n",
    "print(np.linalg.norm(difference))\n",
    "\n",
    "print('SNR:', _pavlovs_SNR(original_gaps[reconstructed_signal_to_evaluate], reconstructed_gaps[reconstructed_signal_to_evaluate], onAxis=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, 4, sharey='row', figsize=(24, 12))\n",
    "\n",
    "original_mag_spec = np.abs(original_stft)\n",
    "rec_mag_spec = np.abs(reconstructed_spec[:, :, :, 0] + 1.0j*reconstructed_spec[:, :, :, 1])\n",
    "\n",
    "rec_mag_to_plot = np.transpose(rec_mag_spec[reconstructed_signal_to_evaluate])\n",
    "window_to_plot = np.transpose(original_mag_spec[reconstructed_signal_to_evaluate])\n",
    "\n",
    "difference = window_to_plot[:, 13:13+11]-rec_mag_to_plot\n",
    "print(window_to_plot.shape)\n",
    "print(rec_mag_to_plot.shape)\n",
    "\n",
    "print(np.zeros(reconstructed_spec[reconstructed_signal_to_evaluate].shape).shape)\n",
    "z_min = np.min(window_to_plot)\n",
    "z_max = np.max(window_to_plot)\n",
    "\n",
    "axarr[0].pcolormesh(window_to_plot, vmin=z_min, vmax=z_max)\n",
    "axarr[0].set_title('original', size=24)\n",
    "axarr[1].pcolormesh(np.concatenate((window_to_plot[:, :13], \n",
    "                                   rec_mag_to_plot, \n",
    "                                   window_to_plot[:, 13+11:]), axis=1), vmin=z_min, vmax=z_max)\n",
    "axarr[1].set_title('reconstructed', size=24)\n",
    "axarr[2].pcolormesh(np.concatenate((window_to_plot[:, :13], \n",
    "                                   np.zeros(rec_mag_to_plot.shape), \n",
    "                                   window_to_plot[:, 13+11:]), axis=1), vmin=z_min, vmax=z_max)\n",
    "axarr[2].set_title('zeroed', size=24)\n",
    "axarr[3].pcolormesh(difference)\n",
    "axarr[3].set_title('difference', size=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_signal_to_evaluate = 3581\n",
    "print('SNR:', _pavlovs_SNR(original_gaps[reconstructed_signal_to_evaluate], reconstructed_gaps[reconstructed_signal_to_evaluate], onAxis=0))\n",
    "\n",
    "IPython.display.Audio(data=reconstructed_signals[reconstructed_signal_to_evaluate], rate=16000)\n",
    "# IPython.display.Audio(data=zeroed_signals[reconstructed_signal_to_evaluate], rate=16000)\n",
    "# IPython.display.Audio(data=audios[reconstructed_signal_to_evaluate], rate=16000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
