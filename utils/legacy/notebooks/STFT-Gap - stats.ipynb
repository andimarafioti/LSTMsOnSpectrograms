{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Encoder\n",
    "\n",
    "Let's begin by importing tensorflow and the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (14, 28)\n",
    "import IPython\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from network.sequentialModel import SequentialModel\n",
    "from network.stftGapContextEncoder import StftGapContextEncoder\n",
    "from utils.strechableNumpyArray import StrechableNumpyArray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize the context encoder network and select the step we want to use for the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000\n",
    "side_length = 2048\n",
    "gap_length = 1024\n",
    "window_size = side_length*2+gap_length\n",
    "\n",
    "batch_size = 256\n",
    "fft_frame_length = 512\n",
    "fft_frame_step = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_step = #complete me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "aTargetModel = SequentialModel(shapeOfInput=(batch_size, window_size), name=\"Target Model\")\n",
    "\n",
    "with tf.name_scope('Remove_unnecesary_sides_before_stft'):\n",
    "    signal = aTargetModel.output()\n",
    "    signal_without_unnecesary_sides = signal[:, 1664:3456]\n",
    "    aTargetModel.setOutputTo(signal_without_unnecesary_sides)\n",
    "aTargetModel.addSTFT(frame_length=fft_frame_length, frame_step=fft_frame_step)\n",
    "aTargetModel.divideComplexOutputIntoRealAndImaginaryParts()  # (256, 11, 257, 2)\n",
    "\n",
    "aModel = SequentialModel(shapeOfInput=(batch_size, window_size), name=\"context encoder\")\n",
    "\n",
    "with tf.name_scope('Remove_gap_before_stft'):\n",
    "    signal = aModel.output()\n",
    "    left_side = signal[:, :2048]\n",
    "    right_side = signal[:, 2048+1024:]\n",
    "    \n",
    "    # This is strange. The window is 5K samples long, the hole 1024 and the 0 pading 384.\n",
    "    # Unless signal in in spectrogram. In that case, the code is not very clear. Maybe consider adding comments.\n",
    "    left_side_padded = tf.concat((left_side, tf.zeros((batch_size, 384))), axis=1)\n",
    "    right_side_padded = tf.concat((tf.zeros((batch_size, 384)), right_side), axis=1)\n",
    "\n",
    "    # If you pad them with 0, maybe you also stack them allong axis 2 (one after the other.)\n",
    "    signal_without_gap = tf.stack((left_side_padded, right_side_padded), axis=1)  # (256, 2, 2432)\n",
    "    aModel.setOutputTo(signal_without_gap)\n",
    "\n",
    "aModel.addSTFT(frame_length=fft_frame_length, frame_step=fft_frame_step)  # (256, 2, 16, 257)\n",
    "aModel.addReshape((batch_size, 32, 257))\n",
    "aModel.divideComplexOutputIntoRealAndImaginaryParts()  # (256, 32, 257, 2)\n",
    "aModel.addReshape((batch_size, 16, 257, 4))\n",
    "\n",
    "with tf.variable_scope(\"Encoder\"):\n",
    "    filter_shapes = [(7, 89), (3, 17), (2, 11), (1, 9), (1, 5), (2, 5)]\n",
    "    input_channels = [4, 32, 128, 512, 256, 160]\n",
    "    output_channels = [32, 128, 512, 256, 160, 128]\n",
    "    strides = [[1, 2, 2, 1], [1, 2, 3, 1], [1, 2, 3, 1], [1, 1, 2, 1], [1, 1, 1, 1], [1, 1, 1, 1]]\n",
    "    names = ['First_Conv', 'Second_Conv', 'Third_Conv', 'Fourth_Conv', 'Fifth_Conv', 'Sixth_Conv']\n",
    "    aModel.addSeveralConvLayers(filter_shapes=filter_shapes, input_channels=input_channels,\n",
    "                                output_channels=output_channels, strides=strides, names=names)\n",
    "\n",
    "aModel.addReshape((batch_size, 2048))\n",
    "aModel.addFullyConnectedLayer(2048, 2048, 'Fully')\n",
    "aModel.addRelu()\n",
    "aModel.addBatchNormalization()\n",
    "aModel.addReshape((batch_size, 8, 8, 32))\n",
    "\n",
    "with tf.variable_scope(\"Decoder\"):\n",
    "    filter_shapes = [(8, 8), (5, 5), (3, 3)]\n",
    "    input_channels = [32, 128, 512]\n",
    "    output_channels = [128, 512, 257]\n",
    "    strides = [[1, 2, 2, 1], [1, 2, 2, 1], [1, 1, 1, 1]]\n",
    "    names = ['First_Deconv', 'Second_Deconv', 'Third_Deconv']\n",
    "    aModel.addSeveralDeconvLayers(filter_shapes=filter_shapes, input_channels=input_channels,\n",
    "                                  output_channels=output_channels, strides=strides, names=names)\n",
    "\n",
    "    aModel.addReshape((batch_size, 8, 257, 128))\n",
    "    aModel.addDeconvLayer(filter_shape=(5, 67), input_channels=128, output_channels=11, stride=(1, 2, 2, 1),\n",
    "                          name='Fourth_deconv')\n",
    "    aModel.addBatchNormalization()\n",
    "\n",
    "    aModel.addReshape((batch_size, 11, 257, 32))\n",
    "\n",
    "    aModel.addDeconvLayerWithoutNonLin(filter_shape=(11, 257), input_channels=32, output_channels=2,\n",
    "                                       stride=(1, 1, 1, 1), name=\"Last_Deconv\")\n",
    "\n",
    "print(aModel.description())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aContextEncoderNetwork = StftGapContextEncoder(model=aModel, batch_size=batch_size, target_model=aTargetModel, window_size=window_size,\n",
    "                                               gap_length=gap_length, learning_rate=1e-4, name='nat_stft_gap_big_fma_2_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = 2\n",
    "test_tfRecord = 'test-fma_w5120_g1024_h512_ex813108.tfrecords'\n",
    "reconstructed_spec, original_spec = aContextEncoderNetwork.reconstruct(data_path=test_tfRecord, \n",
    "                                                                       model_num=test_step, max_steps=batch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reconstructed_spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "rec_stft = reconstructed_spec[:,:,:,0] + 1.0j*reconstructed_spec[:,:,:,1]\n",
    "ori_stft = original_spec[:,:,:,0] + 1.0j*original_spec[:,:,:,1]\n",
    "\n",
    "shape = (batch_size, 11, 257)\n",
    "stft_to_invert = tf.placeholder(tf.complex64, shape=shape, name='stft_to_invert')\n",
    "tf_reconstructed_signals = tf.contrib.signal.inverse_stft(stfts=stft_to_invert, frame_length=fft_frame_length, frame_step=fft_frame_step)\n",
    "\n",
    "reconstructed_signal = np.zeros([0,1792], dtype=float32)\n",
    "original_signal = np.zeros([0,1792], dtype=float32)\n",
    "with tf.Session() as sess:\n",
    "    for i in range(batch_count):\n",
    "        feed_dict = {stft_to_invert: rec_stft[i*batch_size:(i+1)*batch_size]}\n",
    "        reconstructed_signal = np.append(reconstructed_signal, sess.run(tf_reconstructed_signals, feed_dict=feed_dict), axis=0)\n",
    "        \n",
    "        feed_dict = {stft_to_invert: ori_stft[i*batch_size:(i+1)*batch_size]}\n",
    "        original_signal = np.append(original_signal, sess.run(tf_reconstructed_signals, feed_dict=feed_dict), axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_gaps = reconstructed_signal[:, 384:-384]\n",
    "original_gaps = original_signal[:, 384:-384]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reconstructed_signal.shape)\n",
    "print(original_signal.shape)\n",
    "print(reconstructed_spec.shape)\n",
    "print(original_spec.shape)\n",
    "print(len(reconstructed_signal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pavlovs_SNR(y_orig, y_inp, onAxis=(1,)):\n",
    "    norm_y_orig = _squaredEuclideanNorm(y_orig, onAxis)\n",
    "    norm_y_orig_minus_y_inp = _squaredEuclideanNorm(y_orig - y_inp, onAxis)\n",
    "    return 10 * np.log10(norm_y_orig / norm_y_orig_minus_y_inp)\n",
    "\n",
    "def _squaredEuclideanNorm(vector, onAxis=(1,)):\n",
    "    squared = np.square(vector)\n",
    "    summed = np.sum(squared, axis=onAxis)\n",
    "    return summed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_a = reconstructed_gaps\n",
    "gap = original_gaps\n",
    "\n",
    "SNRs = _pavlovs_SNR(gap, fake_a)\n",
    "print('SNRs shape:', SNRs.shape)\n",
    "print('SNRs mean:', SNRs.mean())\n",
    "print('SNRs std:', SNRs.std())\n",
    "print('SNRs min:', SNRs.min())\n",
    "print('SNRs percentiles 25, 50 & 75:', np.percentile(SNRs, [25, 50, 75]))\n",
    "print('SNRs max:', SNRs.max())\n",
    "\n",
    "spec_SNRs = _pavlovs_SNR(original_spec, \n",
    "                   reconstructed_spec, onAxis=(1, 2, 3))\n",
    "\n",
    "print('SNRs on specs mean:', np.mean(spec_SNRs))\n",
    "\n",
    "print('max diff for SNRs on specs:', np.max(np.abs(spec_SNRs-SNRs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_signal_to_evaluate = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, 3, sharey='row', figsize=(18, 12))\n",
    "\n",
    "difference = original_gaps[reconstructed_signal_to_evaluate]-reconstructed_gaps[reconstructed_signal_to_evaluate]\n",
    "\n",
    "axarr[0].plot(original_gaps[reconstructed_signal_to_evaluate])\n",
    "axarr[0].set_title('original gap', size=24)\n",
    "axarr[1].plot(reconstructed_gaps[reconstructed_signal_to_evaluate])\n",
    "axarr[1].set_title('reconstructed gap', size=24)\n",
    "axarr[2].plot(difference)\n",
    "axarr[2].set_title('difference', size=24)\n",
    "\n",
    "print(np.sum(np.absolute(original_gaps[reconstructed_signal_to_evaluate])))\n",
    "print(np.absolute(difference).sum())\n",
    "print(np.linalg.norm(difference))\n",
    "\n",
    "print('SNR:', _pavlovs_SNR(original_gaps[reconstructed_signal_to_evaluate], reconstructed_gaps[reconstructed_signal_to_evaluate], onAxis=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, 4, sharey='row', figsize=(24, 12))\n",
    "\n",
    "original_mag_spec = np.abs(original_spec[:, :, :, 0] + 1.0j*original_spec[:, :, :, 1])\n",
    "rec_mag_spec = np.abs(reconstructed_spec[:, :, :, 0] + 1.0j*reconstructed_spec[:, :, :, 1])\n",
    "\n",
    "rec_mag_to_plot = np.transpose(rec_mag_spec[reconstructed_signal_to_evaluate])\n",
    "window_to_plot = np.transpose(original_mag_spec[reconstructed_signal_to_evaluate])\n",
    "\n",
    "difference = window_to_plot-rec_mag_to_plot\n",
    "print(window_to_plot.shape)\n",
    "print(rec_mag_to_plot.shape)\n",
    "\n",
    "print(np.zeros(reconstructed_spec[reconstructed_signal_to_evaluate].shape).shape)\n",
    "z_min = np.min(window_to_plot)\n",
    "z_max = np.max(window_to_plot)\n",
    "\n",
    "axarr[0].pcolormesh(window_to_plot, vmin=z_min, vmax=z_max)\n",
    "axarr[0].set_title('original', size=24)\n",
    "axarr[1].pcolormesh(rec_mag_to_plot, vmin=z_min, vmax=z_max)\n",
    "axarr[1].set_title('reconstructed', size=24)\n",
    "axarr[2].pcolormesh(np.zeros(rec_mag_to_plot.shape), vmin=z_min, vmax=z_max)\n",
    "axarr[2].set_title('zeroed', size=24)\n",
    "axarr[3].pcolormesh(difference, vmin=z_min, vmax=z_max)\n",
    "axarr[3].set_title('difference', size=24)\n",
    "\n",
    "# real_for_snr = np.stack((np.real(original_stft[:, 13:24]), np.imag(original_stft[:, 13:24])),axis=-1)\n",
    "print(_pavlovs_SNR(original_spec[reconstructed_signal_to_evaluate], reconstructed_spec[reconstructed_signal_to_evaluate], onAxis=(0,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_SNRs = _pavlovs_SNR(ori_stft, \n",
    "                   rec_stft, onAxis=(1, 2))\n",
    "\n",
    "mag_SNRs = _pavlovs_SNR(np.abs(ori_stft), np.abs(rec_stft), onAxis=(1, 2))\n",
    "phase_SNRs = _pavlovs_SNR(np.angle(ori_stft), np.angle(rec_stft), onAxis=(1, 2))\n",
    "\n",
    "phasetimesmag_SNRs = _pavlovs_SNR(np.angle(ori_stft)*np.abs(ori_stft), np.abs(rec_stft)*np.angle(rec_stft), onAxis=(1, 2))\n",
    "\n",
    "stft_channels_SNRs = _pavlovs_SNR(original_spec, \n",
    "                   reconstructed_spec, onAxis=(1, 2, 3))\n",
    "\n",
    "print('SNRs on stft per channel mean:', np.mean(stft_channels_SNRs))\n",
    "print('SNRs on stft mean:', np.mean(stft_SNRs))\n",
    "print('SNRs on mag mean:', np.mean(mag_SNRs))\n",
    "print('SNRs on phase mean:', np.mean(phase_SNRs))\n",
    "print('SNRs on phase times mag mean:', np.mean(phasetimesmag_SNRs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted_SNR = sorted(SNRs)\n",
    "\n",
    "import scipy.stats as stats\n",
    "fit = stats.norm.pdf(sorted_SNR, np.mean(sorted_SNR), np.std(sorted_SNR))  #this is a fitting indeed\n",
    "\n",
    "plt.plot(sorted_SNR,fit,'-o')\n",
    "\n",
    "plt.hist(sorted_SNR, 50, normed=True)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
